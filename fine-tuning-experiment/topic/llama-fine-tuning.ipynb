{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import re\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from huggingface_hub import interpreter_login\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment\n",
    "The code is adapted from unlslothai's work available at https://github.com/unslothai/unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all remaining data (data not included in prompt selection or prompting experiment): text, label\n",
    "data = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# Authenticate with Huggingface token\n",
    "#!git config --global credential.helper store\n",
    "interpreter_login()\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" \n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for confidence scores\n",
    "topic_v3_prompt_confidence = \"\"\"\n",
    "Du er en gennemsnitlig dansk nyhedsforbruger. Du får en artikel, og skal tildele den et passende antal kategorier svarende til de emner den omhandler. Artiklen omhandler oftest flere emner, men en kan også kun omhandle ét emne. \n",
    "Her er nogle generelle principper, du skal følge: Du skal anvende generel verdensviden og artiklens kontekst, hvor det er nødvendigt. Et emne skal bidrage med at fremføre artiklens væsentligste pointer for at kategorien tildeles. Det er muligt at samtagge flere kategorier, så to kategorier tilsammen skaber det emne, artiklen omhandler.\n",
    "Kategorier: ”Begivenhed”: En hændelse, der finder sted - særligt for at markere noget vigtigt og evt. tilbagevendende. Herunder mærkedag, personlig begivenhed, sportsbegivenhed og underholdningsbegivenhed. ”Bolig”: Privatpersoners hjem. Herunder køb og salg, renovering/indretning og udlejning. ”Erhverv”: Emner relateret til beskæftigelsesmæssige forhold, inkl. arbejdspladser. Herunder ansættelsesforhold, offentlig instans og privat virksomhed. ”Dyr”: Levende flercellede organismer, ekskl. planter og mennesker. ”Katastrofe”: Begivenheder, som har negative konsekvenser for en større eller mindre gruppe (mennesker). Herunder mindre ulykke og større katastrofe. ”Kendt”: Personer, som ofte er alment kendt blandt den brede befolkning, fx deltagere i tv-programmer, politikere, sportspersonligheder, toperhvervsfolk og kongelige. ”Konflikt og krig”: Sammenstød, uoverensstemmelser eller stridigheder mellem to eller flere parter - evt. med voldelige konsekvenser. Herunder terror og væbnet konflit. ”Kriminalitet”: Ulovligheder, der omhandler fx dramatiske, dødelige eller sindsoprivende begivenheder, hvori politiet evt. har været involveret. Herunder bandekriminalitet, bedrageri og personfarlig kriminalitet. ”Kultur”: Den levevis, som er resultat af menneskelig aktivitet, og forestillingsverden, herunder skikke, holdninger og traditioner, ved en bestemt befolkningsgruppe i en bestemt periode. Herunder byliv, kunst, museum og seværdighed, or rejse. ”Livsstil”: Den bevidst valgte levemåde, som (en) privatperson(er) har - ofte for at signalere en bestemt identitet. Herunder erotik, familieliv, fritid, krop og velvære, mad og drikke og partnerskab. ”Politik”: Samfundsrelevante problemstillinger, værdier o.lign., som udføres på baggrund af en bestemt ideologi. Herunder international politik og national politik. ”Samfund”: Forhold for mennesker, der typisk deler samme geografiske område og/eller er knyttet sammen på anden vis, fx gennem indbyrdes afhængighed og tilknytning til nationalstat. Herunder bæredygtighed og klima, værdier, religion og tendens. ”Sport”: (Fysisk) aktivitet, som udøves individuelt eller på hold i professionelle sammenhænge, og hvor der ofte indgår specifikke regler og evt. udstyr. Herunder cykling, håndbold, fodbold, ketcher- og batsport og motorsport. ”Sundhed”: Helbredsmæssige forhold. Herunder kosmetisk behandling og sygdom og behandling. Teknologi”: Beskrivelser og anvendelser af tekniske hjælpemidler til udførelse af opgaver. Herunder forbrugerelektronik, kunstig intelligens og software. ”Transportmiddel”: Førbare anordninger, som kan fragte levende væsener og/eller artefakter. Herunder bil, mindre transportmiddel, offentlig transport og større transportmiddel. ”Uddannelse”: Strukturerede undervisningsforløb. Herunder grundskole, ungdomsuddannelse og videregående uddannelse. \"Underholdning”: Forhold med evne til at more/frembringe glæde hos modtageren. Herunder litteratur, film og tv, musik og lyd og reality. ”Vejr”: Meterologiske forhold, fx forudsigelse eller afrapportering, ofte omhandlende et bestemt geografisk område på et bestemt tidspunkt. \"Videnskab”: Metodologisk forskning og undersøgelse af bestemte dele af virkeligheden. Herunder naturvidenskab og samfundsvidenskab og humaniora. ”Økonomi”: Produktion, fordeling og forbrug (hos både privatpersoner og på statsligt niveau) af varer og tjenester. Herunder makroøkonomi og mikroøkonomi. \n",
    "Giv også en confidence score med to decimaler fra 0.00 til 1.00, der repræsenterer hvor sikker du er i din vurdering af sentiment, hvor 0 er meget usikker og 1 er meget sikker.\n",
    "Giv et præcist svar i json: {{topics: [”kategori”, ”kategori”, ”kategori”, ... ], \"confidence\": \"score\"}}. Det er meget vigtigt, at du kun returnerer dette format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run Llama with few-shot prompts\n",
    "def fewshot_topic_annotation(text, prompt, fewshot_dataset):\n",
    "    # Sample few-shot examples from dataset without current article\n",
    "    fewshot_dataset = fewshot_dataset[fewshot_dataset['text'] != text]\n",
    "    fewshot_examples = fewshot_dataset.sample(1).to_dict(orient='records')\n",
    "    # Create few-shot part of prompt\n",
    "    fewshot_examples = \"\\n\".join([f\"Artikel: {example['text']}. Artiklen omhandler dette/disse emne(r): {example['label']}.\" for example in fewshot_examples])\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{prompt}. Her er et eksempel på en artikel og dens emner: {fewshot_examples}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Artikel: {text}. Artiklen omhandler dette/disse emne(r): \"},\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    "    \n",
    "    # Return the generated content\n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply few-shot\n",
    "data[\"llm_annotation\"] = data[\"text\"].apply(lambda text: fewshot_topic_annotation(text, prompt=topic_v3_prompt_confidence, fewshot_dataset=data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract confidence scores\n",
    "def extract_confidence(value):\n",
    "    match = re.search(r'\"confidence\":\\s*\"?(\\d+\\.\\d+)\"?', str(value))\n",
    "    if match:\n",
    "        return int(float(match.group(1)))\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "data[\"confidence_scores\"] = data[\"llm_annotation\"].apply(extract_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format topics from strings to lists\n",
    "def annotation_to_list(annotation):\n",
    "    annotation_list = []\n",
    "    \n",
    "    topics = [\"Begivenhed\", \"Bolig\", \"Erhverv\", \"Dyr\", \"Katastrofe\", \"Kendt\", \"Konflikt og krig\", \"Kriminalitet\", \"Kultur\", \"Livsstil\",\n",
    "          \"Politik\", \"Samfund\", \"Sport\", \"Sundhed\", \"Teknologi\", \"Transportmiddel\", \"Uddannelse\", \"Underholdning\", \"Vejr\", \"Videnskab\", \"Økonomi\"]\n",
    "\n",
    "    # Regular expression to capture words inside single/double quotes or just words\n",
    "    annotation_topics = [topic.lower() for topic in re.findall(r'[\"\\']?([a-zA-ZæøåÆØÅ\\s]+)[\"\\']?', annotation)]\n",
    "    \n",
    "    # Iterate over the topics and check for case-insensitive matches in the extracted topics\n",
    "    for topic in topics:\n",
    "        if topic.lower() in annotation_topics:\n",
    "            annotation_list.append(topic)\n",
    "    \n",
    "    return annotation_list\n",
    "\n",
    "data[\"label\"] = data[\"label\"].apply(annotation_to_list)\n",
    "data[\"llm_annotation\"] = data[\"llm_annotation\"].apply(annotation_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels for confidence intervals\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = [\"0-0.1\", \"0.1-0.2\", \"0.2-0.3\", \"0.3-0.4\", \"0.4-0.5\", \"0.5-0.6\", \"0.6-0.7\", \"0.7-0.8\", \"0.8-0.9\", \"0.9-1.0\"]\n",
    "data[\"confidence_interval\"] = pd.cut(data[\"confidence_scores\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Determine correctness of LLM annotations\n",
    "def classify_correctness(row):\n",
    "    human_set = set(row[\"label\"])\n",
    "    llm_set = set(row[\"llm_annotation\"])\n",
    "    if human_set == llm_set:\n",
    "        return \"correct\"\n",
    "    elif human_set & llm_set:\n",
    "        return \"partially_correct\"\n",
    "    else:\n",
    "        return \"incorrect\"\n",
    "\n",
    "data[\"is_correct\"] = data.apply(classify_correctness, axis=1)\n",
    "\n",
    "# Calculate proportions for each group based on available data\n",
    "group_counts = data.groupby([\"confidence_interval\", \"is_correct\"]).size()\n",
    "total_available = group_counts.sum()\n",
    "group_proportions = group_counts / total_available\n",
    "\n",
    "# Calculate target sample sizes based on the proportions\n",
    "total_samples = 300\n",
    "sample_sizes = (group_proportions * total_samples).round().astype(int)\n",
    "\n",
    "# Initialize an empty DataFrame for the sampled data\n",
    "sampled_df = pd.DataFrame()\n",
    "\n",
    "# Sample examples from each group without replacement\n",
    "for (interval, correct), size in sample_sizes.items():\n",
    "    if size > 0:\n",
    "        # Subset data for this group\n",
    "        group_data = data[(data[\"confidence_interval\"] == interval) & (data[\"is_correct\"] == correct)]\n",
    "        \n",
    "        # Sample without replacement, up to the size of the group\n",
    "        if len(group_data) >= size:\n",
    "            sampled_group = group_data.sample(n=size, random_state=42, replace=False)\n",
    "        else:\n",
    "            # If not enough examples, sample all available examples\n",
    "            sampled_group = group_data\n",
    "            print(f\"Warning: Not enough examples in group ({interval}, {correct}). Adding all {len(group_data)} examples.\")\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df, sampled_group])\n",
    "\n",
    "# Reset index for the sampled DataFrame\n",
    "sampled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data = sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 5000 \n",
    "dtype = None \n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = os.getenv(\"HUGGINGFACE_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = True, \n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format fine-tuning data to chat template\n",
    "data[\"text\"] = data[\"messages\"].apply(lambda chat: tokenizer.apply_chat_template(chat, tokenize=False))\n",
    "\n",
    "# convert to Huggingface dataset\n",
    "data_dict = {\"text\": data[\"text\"].tolist()}\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_steps = 10,\n",
    "        max_steps = 100,\n",
    "        learning_rate = 1e-5, \n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 5,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation data\n",
    "evaluation_data = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V0 zeroshot \n",
    "def run_v0_topic_inference(text, model):\n",
    "\n",
    "    # Define the chat input, inserting the text. v3 prompt    \n",
    "    chat_input = [\n",
    "        f'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n'\n",
    "        f'Cutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n'\n",
    "        f'Du er en gennemsnitlig dansk nyhedsforbruger. Du får en artikel, og skal tildele den et passende antal kategorier svarende til de emner den omhandler.'\n",
    "        f'Artiklen omhandler oftest flere emner, men den kan også omhandle kun et emne. '\n",
    "        f'Kategorier: ”Begivenhed”, ”Bolig”, ”Erhverv”, ”Dyr”, ”Katastrofe”, ”Kendt”, ”Konflikt og krig”, ”Kriminalitet”, ”Kultur”, ”Livsstil”, ”Politik”, ”Samfund”, ”Sport”, ”Sundhed”, ”Teknologi”, ”Transportmiddel”, ”Uddannelse”, ”Underholdning”, ”Vejr”, ”Videnskab”, ”Økonomi”. '\n",
    "        f'Giv et præcist svar i json: {{emner: [”kategori”, ”kategori”, ”kategori”, ... ]}}.<|eot_id|><|start_header_id|>user<|end_header_id>\\n\\n'\n",
    "        f'Artikel: {text} \\nArtiklen omhandler dette/disse emne(r):<|eot_id|><|start_header_id|>assistant<|end_header_id>\\n\\n'\n",
    "    ]\n",
    "\n",
    "    # Tokenize the chat input for the model\n",
    "    inputs = tokenizer(chat_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate the output\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "\n",
    "    # Decode the generated output\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return decoded_outputs\n",
    "\n",
    "evaluation_data[\"v0-zeroshot-annotation\"] = evaluation_data[\"text\"].apply(lambda text: run_v0_topic_inference(text, model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V3 few-shot\n",
    "def run_v3_fewshot_topic_inference(text, model, fewshot_dataset):\n",
    "    # Sample few-shot examples from dataset without current article\n",
    "    fewshot_dataset = fewshot_dataset[fewshot_dataset['text'] != text]\n",
    "    fewshot_examples = fewshot_dataset.sample(1).to_dict(orient='records')\n",
    "    # Create few-shot part of prompt\n",
    "    fewshot_example = \"\\n\".join([f\"Artikel: {example['text']}. Artiklen omhandler dette/disse emne(r): {example['label']}.\" for example in fewshot_examples])\n",
    "    \n",
    "    # Define the chat input, inserting the text. v3 prompt    \n",
    "    chat_input = [\n",
    "        f'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n'\n",
    "        f'Cutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n'\n",
    "        f'Du er en gennemsnitlig dansk nyhedsforbruger. Du får en artikel, og skal tildele den et passende antal kategorier svarende til de emner den omhandler. Artiklen omhandler oftest flere emner, men en kan også kun omhandle ét emne.'\n",
    "        f'Her er nogle generelle principper, du skal følge: Du skal anvende generel verdensviden og artiklens kontekst, hvor det er nødvendigt. Et emne skal bidrage med at fremføre artiklens væsentligste pointer for at kategorien tildeles. Det er muligt at samtagge flere kategorier, så to kategorier tilsammen skaber det emne, artiklen omhandler.'\n",
    "        f'Kategorier: ”Begivenhed”: En hændelse, der finder sted - særligt for at markere noget vigtigt og evt. tilbagevendende. Herunder mærkedag, personlig begivenhed, sportsbegivenhed og underholdningsbegivenhed. ”Bolig”: Privatpersoners hjem. Herunder køb og salg, renovering/indretning og udlejning. ”Erhverv”: Emner relateret til beskæftigelsesmæssige forhold, inkl. arbejdspladser. Herunder ansættelsesforhold, offentlig instans og privat virksomhed. ”Dyr”: Levende flercellede organismer, ekskl. planter og mennesker. ”Katastrofe”: Begivenheder, som har negative konsekvenser for en større eller mindre gruppe (mennesker). Herunder mindre ulykke og større katastrofe. ”Kendt”: Personer, som ofte er alment kendt blandt den brede befolkning, fx deltagere i tv-programmer, politikere, sportspersonligheder, toperhvervsfolk og kongelige. ”Konflikt og krig”: Sammenstød, uoverensstemmelser eller stridigheder mellem to eller flere parter - evt. med voldelige konsekvenser. Herunder terror og væbnet konflit. ”Kriminalitet”: Ulovligheder, der omhandler fx dramatiske, dødelige eller sindsoprivende begivenheder, hvori politiet evt. har været involveret. Herunder bandekriminalitet, bedrageri og personfarlig kriminalitet. ”Kultur”: Den levevis, som er resultat af menneskelig aktivitet, og forestillingsverden, herunder skikke, holdninger og traditioner, ved en bestemt befolkningsgruppe i en bestemt periode. Herunder byliv, kunst, museum og seværdighed, or rejse. ”Livsstil”: Den bevidst valgte levemåde, som (en) privatperson(er) har - ofte for at signalere en bestemt identitet. Herunder erotik, familieliv, fritid, krop og velvære, mad og drikke og partnerskab. ”Politik”: Samfundsrelevante problemstillinger, værdier o.lign., som udføres på baggrund af en bestemt ideologi. Herunder international politik og national politik. ”Samfund”: Forhold for mennesker, der typisk deler samme geografiske område og/eller er knyttet sammen på anden vis, fx gennem indbyrdes afhængighed og tilknytning til nationalstat. Herunder bæredygtighed og klima, værdier, religion og tendens. ”Sport”: (Fysisk) aktivitet, som udøves individuelt eller på hold i professionelle sammenhænge, og hvor der ofte indgår specifikke regler og evt. udstyr. Herunder cykling, håndbold, fodbold, ketcher- og batsport og motorsport. ”Sundhed”: Helbredsmæssige forhold. Herunder kosmetisk behandling og sygdom og behandling. Teknologi”: Beskrivelser og anvendelser af tekniske hjælpemidler til udførelse af opgaver. Herunder forbrugerelektronik, kunstig intelligens og software. ”Transportmiddel”: Førbare anordninger, som kan fragte levende væsener og/eller artefakter. Herunder bil, mindre transportmiddel, offentlig transport og større transportmiddel. ”Uddannelse”: Strukturerede undervisningsforløb. Herunder grundskole, ungdomsuddannelse og videregående uddannelse. \"Underholdning”: Forhold med evne til at more/frembringe glæde hos modtageren. Herunder litteratur, film og tv, musik og lyd og reality. ”Vejr”: Meterologiske forhold, fx forudsigelse eller afrapportering, ofte omhandlende et bestemt geografisk område på et bestemt tidspunkt. \"Videnskab”: Metodologisk forskning og undersøgelse af bestemte dele af virkeligheden. Herunder naturvidenskab og samfundsvidenskab og humaniora. ”Økonomi”: Produktion, fordeling og forbrug (hos både privatpersoner og på statsligt niveau) af varer og tjenester. Herunder makroøkonomi og mikroøkonomi. '\n",
    "        f'Her er et eksempel på en artikel og emner: {fewshot_example}'\n",
    "        f'Giv et præcist svar i json: {{topics: [”kategori”, ”kategori”, ”kategori”, ... ]}}.<|eot_id|><|start_header_id|>user<|end_header_id>\\n\\n'\n",
    "        f'Artikel: {text} \\nArtiklen omhandler dette/disse emne(r):<|eot_id|><|start_header_id|>assistant<|end_header_id>\\n\\n'\n",
    "    ]\n",
    "\n",
    "    # Tokenize the chat input for the model\n",
    "    inputs = tokenizer(chat_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate the output\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "\n",
    "    # Decode the generated output\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return decoded_outputs\n",
    "\n",
    "evaluation_data[\"v3-fewshot-annotation\"] = evaluation_data[\"text\"].apply(lambda text: run_v3_fewshot_topic_inference(text, model=model, fewshot_dataset=evaluation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topics from LLM output\n",
    "def extract_topics(target, reference):\n",
    "    index = reference.find(target)\n",
    "    if index == -1:\n",
    "        # Target string not found\n",
    "        return \"\"\n",
    "    # Return everything after the target string\n",
    "    return reference[index + len(target):]\n",
    "\n",
    "# Apply the function to the first element ([0]) of each list in the Series\n",
    "evaluation_data[\"llm_annotation_v3-fewshot-annotation\"] = evaluation_data[\"v3-fewshot-annotation\"].apply(\n",
    "    lambda x: extract_topics(\"assistant<|end_header_id>\", x[0]) if isinstance(x, list) and len(x) > 0 else \"\"\n",
    ")\n",
    "\n",
    "evaluation_data[\"llm_annotation_v0-zeroshot-annotation\"] = evaluation_data[\"v0-zeroshot-annotation\"].apply(\n",
    "    lambda x: extract_topics(\"assistant<|end_header_id>\", x[0]) if isinstance(x, list) and len(x) > 0 else \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation results in csv\n",
    "evaluation_data.to_csv(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
